{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "under-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/3474382/how-do-i-run-two-python-loops-concurrently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "advisory-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/real-time-eye-tracking-using-opencv-and-dlib-b504ca724ac6\n",
    "# https://medium.com/@stepanfilonov/tracking-your-eyes-with-python-3952e66194a6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "relative-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # OpenCV\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from PIL import Image\n",
    "import dlib\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.spatial import distance as dist\n",
    "import mediapipe as mp\n",
    "from skimage.color import rgb2hsv\n",
    "import glob\n",
    "from imutils import face_utils\n",
    "import skimage.color\n",
    "import skimage.io\n",
    "import os, os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "athletic-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haar(frame,rgb):\n",
    "    # opencv object that will detect faces for us\n",
    "    face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_alt.xml')\n",
    "\n",
    "\n",
    "    front = face_cascade.detectMultiScale(\n",
    "        rgb,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5,\n",
    "        minSize=(100, 100),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "    \n",
    "    pyplot.imshow(rgb)\n",
    "    # get the context for drawing boxes\n",
    "    \n",
    "    ax = pyplot.gca()\n",
    "    \n",
    "\n",
    "    for (x, y, w, h) in front:\n",
    "        # for each face on the image detected by OpenCV\n",
    "        # draw a rectangle around the face\n",
    "        cv2.rectangle(frame, \n",
    "                      (x, y), # start_point\n",
    "                      (x+w, y+h), # end_point\n",
    "                      (255, 0, 0),  # color in BGR\n",
    "                      2) # thickness in px\n",
    "        rect = Rectangle((x, y), w, h, fill=False, color='green', linewidth = 2)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        print(\"Haar height is \" + str(h))\n",
    "        print(\"Haar width is \" + str(w))\n",
    "        cv2.rectangle(rgb,(x,y),(x+w,y+h),(0,255,0), 2)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,'Haar Detection Completed',(x,y), font, 1, (0, 63, 123),2)\n",
    "        \n",
    "        print('Haar coordinate: width = ' + str(x) + 'to' + str(x+w))\n",
    "        print('Haar coordinate: height = ' + str(y) + 'to'  + str(y+h))\n",
    "      \n",
    "        return(x,y,w,h)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fresh-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to draw HOG bounding box\n",
    "def convert_and_trim_bb(image, rect):\n",
    "    # extract the starting and ending (x, y)-coordinates of the\n",
    "    # bounding box\n",
    "    startX = rect.left()\n",
    "    startY = rect.top()\n",
    "    endX = rect.right()\n",
    "    endY = rect.bottom()\n",
    "\n",
    "    # ensure the bounding box coordinates fall within the spatial\n",
    "    # dimensions of the image\n",
    "    startX = max(0, startX)\n",
    "    startY = max(0, startY)\n",
    "    endX = min(endX, image.shape[1])\n",
    "    endY = min(endY, image.shape[0])\n",
    "\n",
    "    # compute the width and height of the bounding box\n",
    "    w = endX - startX\n",
    "    h = endY - startY\n",
    "\n",
    "    # return our bounding box coordinates\n",
    "    return (startX, startY, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "provincial-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog(frame,rgb):\n",
    "\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    rects = detector(rgb)\n",
    "\n",
    "    pyplot.imshow(rgb)\n",
    "#     ax = pyplot.gca()\n",
    "\n",
    "    boxes = [convert_and_trim_bb(rgb, r) for r in rects]\n",
    "    \n",
    "    \n",
    "    \n",
    "    for (x, y, w, h) in boxes:\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), ( 255, 255, 255), 2)\n",
    "        cv2.rectangle(rgb,(x,y),(x+w,y+h),(255,0,255), 2)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,'HOG Detection Completed',(x,y), font, 1, (184,53,255),2)\n",
    "        \n",
    "        print(\"HOG height is \" + str(h))\n",
    "        print(\"HOG width is \" + str(w))\n",
    "        \n",
    "        print('HOG coordinate: width = ' + str(x) + 'to' + str(x+w))\n",
    "        print('HOG coordinate: height = ' + str(y) + 'to' + str(y + h))\n",
    "      \n",
    "            \n",
    "        \n",
    "        return(x,y,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "immediate-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtcnn(frame,rgb):\n",
    "    detector = MTCNN()\n",
    "    faces = detector.detect_faces(frame)\n",
    "\n",
    "    pyplot.imshow(rgb)\n",
    "    # get the context for drawing boxes\n",
    "    ax = pyplot.gca()\n",
    "    # plot each box\n",
    "    for result in faces:\n",
    "        # get coordinates\n",
    "        x, y, width, height = result['box']\n",
    "        # create the shape\n",
    "\n",
    "        print(\"MTCNN height is \" + str(height))\n",
    "        print(\"MTCNN width is \" + str(width))\n",
    "        \n",
    "        # draw the box\n",
    "        \n",
    "        cv2.rectangle(frame,(x,y),(x+width,y+height),(0,255,0),2)\n",
    "        cv2.rectangle(rgb,(x,y),(x+width,y+height), (255,150,0), 2)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,'MTCNN Detection Completed',(x,y), font, 1, (0,0,255),2)\n",
    "            \n",
    "        print('MTCNN coordinate: width = ' + str(x) + 'to' + str(x + width))\n",
    "        print('MTCNN coordinate: height = ' + str(y) + 'to' + str(y + height))\n",
    "        \n",
    "        \n",
    "        return(x,y,width,height)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intended-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint(ptA, ptB):\n",
    "\treturn ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "latin-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Euclidean distance to find distance from center of eye to each side of bounding box\n",
    "def top_head(rgb,detector,eye_centerX,eye_centerY):\n",
    "    cv2.line(rgb, (int(eye_centerX), int(detector[1])), (int(eye_centerX), int(eye_centerY)),\n",
    "                        (255,255,255), 2)\n",
    "    D_top = dist.euclidean((eye_centerX, detector[1]), (eye_centerX, eye_centerY)) \n",
    "                    \n",
    "\n",
    "    return(D_top)\n",
    "\n",
    "\n",
    "def left_head(rgb,detector,eye_centerX,eye_centerY):\n",
    "    cv2.line(rgb, (int(detector[0]+detector[2]), int(eye_centerY)), (int(eye_centerX), int(eye_centerY)),\n",
    "                    (255,255,255), 2)\n",
    "    D_left = dist.euclidean((detector[0]+detector[2], eye_centerY), (eye_centerX, eye_centerY))\n",
    "\n",
    "    return(D_left)\n",
    "\n",
    "\n",
    "\n",
    "def right_head(rgb,detector,eye_centerX,eye_centerY):\n",
    "    \n",
    "    cv2.line(rgb, (int(detector[0]), int(eye_centerY)), (int(eye_centerX), int(eye_centerY)),\n",
    "                        (255,255,255), 2)\n",
    "    D_right = dist.euclidean((detector[0], eye_centerY), (eye_centerX, eye_centerY)) \n",
    "    \n",
    "    return(D_right)\n",
    "\n",
    "\n",
    "def bot_head(rgb,detector,eye_centerX,eye_centerY):\n",
    "    cv2.line(rgb, (int(eye_centerX), int(detector[1] + detector[3])), (int(eye_centerX), int(eye_centerY)),\n",
    "                        (255,255,255), 2)\n",
    "    D_bot = dist.euclidean((eye_centerX, detector[1] + detector[3]), (eye_centerX, eye_centerY)) \n",
    "    return(D_bot)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "military-beginning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye(frame, rgb):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "#     right = [36, 37, 38, 39, 40, 41]\n",
    "#     left = [42, 43, 44, 45, 46, 47]\n",
    "    kernel = np.ones((9, 9), np.uint8)\n",
    "#     img = cv2.imread(filename)\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = frame.copy()\n",
    "    rects = detector(rgb, 1)\n",
    "    for rect in rects:\n",
    "        \n",
    "            \n",
    "        shape = predictor(frame, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        \n",
    "        #Finding the coordinates of the center of left eye\n",
    "        mid_left_x = (shape[43][0]+(shape[46][0]))/2\n",
    "        mid_left_y = (shape[43][1]+(shape[46][1]))/2\n",
    "        eye_left_cord = mid_left_x, mid_left_y\n",
    "        cv2.line(rgb, (int(mid_left_x), int(mid_left_y)), (int(mid_left_x), int(mid_left_y)), (255, 0, 0), 10)\n",
    "        cv2.line(frame, (int(mid_left_x), int(mid_left_y)), (int(mid_left_x), int(mid_left_y)), (0, 0, 255), 10)\n",
    "    \n",
    "        #Finding the coordinates of the center of right eye\n",
    "        mid_right_x = (shape[37][0]+(shape[40][0]))/2\n",
    "        mid_right_y = (shape[37][1]+(shape[40][1]))/2\n",
    "        eye_right_cord = mid_right_x, mid_right_y\n",
    "        cv2.line(rgb, (int(mid_right_x), int(mid_right_y)), (int(mid_right_x), int(mid_right_y)), (255, 0, 0), 10)\n",
    "        cv2.line(frame, (int(mid_right_x), int(mid_right_y)), (int(mid_right_x), int(mid_right_y)), (0, 0, 255), 10)\n",
    "        \n",
    "\n",
    "        return mid_left_x, mid_left_y, eye_left_cord, mid_right_x, mid_right_y, eye_right_cord\n",
    "            \n",
    "    plt.figure(1)\n",
    "    plt.imshow(rgb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "accepted-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cropping the features according to assigned points\n",
    "def crop(mesh_coor, indices,rgb):\n",
    "    mask = np.zeros(rgb.shape[:2],np.uint8)\n",
    "    pts = np.array([[mesh_coor[p] for p in indices]] )\n",
    "\n",
    "    cv2.fillPoly(mask,pts,(255))\n",
    "\n",
    "    dst = cv2.bitwise_and(rgb,rgb,mask=mask)\n",
    "\n",
    "    rect = cv2.boundingRect(pts)\n",
    "    x,y,w,h = rect\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        roi = rgb[y:y+h,x:x+w]\n",
    "#         plt.figure()\n",
    "#         plt.imshow(roi)\n",
    "\n",
    "    except:\n",
    "        print(\"Cropped feature too small\")\n",
    "\n",
    "    try:\n",
    "        cropped = dst[y:y+h,x:x+w]\n",
    "        plt.figure()\n",
    "        plt.imshow(cropped)\n",
    "\n",
    "    except:\n",
    "        print(\"Cropped feature too small\")\n",
    "       \n",
    "    gray = cv2.cvtColor(cropped,cv2.COLOR_RGB2GRAY)\n",
    "    mask_g = cv2.threshold(gray,250,255,cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    mask_g = 255 - mask_g\n",
    "\n",
    "     #Remove noise\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    mask = cv2.morphologyEx(mask_g,cv2.MORPH_OPEN,kernel)\n",
    "    mask = cv2.morphologyEx(mask_g,cv2.MORPH_OPEN,kernel)\n",
    "\n",
    "    result = cropped.copy()\n",
    "    result = cv2.cvtColor(result,cv2.COLOR_RGB2RGBA)\n",
    "    result[:,:,3] = mask\n",
    "\n",
    "    return result, result.shape, roi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "consolidated-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_mesh(face):\n",
    "    NUM_FACE = 2\n",
    "    mpDraw = mp.solutions.drawing_utils\n",
    "    mpFaceMesh = mp.solutions.face_mesh\n",
    "    faceMesh = mpFaceMesh.FaceMesh(max_num_faces = NUM_FACE)\n",
    "    drawSpec = mpDraw.DrawingSpec(thickness = 1, circle_radius = 1)\n",
    "    \n",
    "    #Commented points are just in case some parts of face(s) get cut / not all points in mesh gets detected \n",
    "    RIGHT_CHEEK = [233,232,231,230,229,228, 31,226,35,143,34,127,227,137,177,215,58,172,136,210,202,43,92,203,142,126,217,114,128]\n",
    "#     RIGHT_CHEEK = [233,232,231,230,229,228, 31,111,116,123,147,213,192,210,202,43,92,203,142,126,217,114,128]\n",
    "    LEFT_CHEEK = [452, 451, 450, 449,448,261,265,372,447,366,401,435,367,364, 430,422,371,277,350]\n",
    "#     LEFT_CHEEK = [452, 451, 450, 449,448,261,265,372,345,352,376,416,430,422,371,277,350]\n",
    "    CHIN = [43,106,182,83,18,313,406,335,273,422, 430, 394, 379,378,400,377,152,148,176,149,150,169,210,202]\n",
    "#     CHIN = [43,106,182,83,18,313,406,335,273,422, 430, 394, 379,378,369,428,199,208,140,149,150,169,210,202]\n",
    "    FOREHEAD = [21,54,103,67,109,10,338,297,332,284,251,368,383,300,293,334,296,336,285,417,168,193,55,107,66,105,63,70,71]\n",
    "    # RIGHT_EYE=[ 33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161 , 246 ]  \n",
    "\n",
    "    \n",
    "\n",
    "    rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "    clone = rgb.copy()\n",
    "    results = faceMesh.process(face)\n",
    "    \n",
    "    if results.multi_face_landmarks:\n",
    "        for faceLms in results.multi_face_landmarks:\n",
    "            mpDraw.draw_landmarks(clone,faceLms,mpFaceMesh.FACEMESH_TESSELATION,drawSpec,drawSpec)\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(clone)\n",
    "            plt.grid(False)\n",
    "\n",
    "\n",
    "    img_height, img_width,ic = rgb.shape\n",
    "\n",
    "    \n",
    "    try:\n",
    "        mesh_coord = [(int(point.x * img_width), int(point.y * img_height)) for point in results.multi_face_landmarks[0].landmark]\n",
    "\n",
    "\n",
    "        cv2.polylines(rgb,  [np.array([mesh_coord[p] for p in LEFT_CHEEK ], dtype=np.int32)], True,(0,255,0), 2, cv2.LINE_AA)\n",
    "        cv2.polylines(rgb,  [np.array([mesh_coord[p] for p in RIGHT_CHEEK ], dtype=np.int32)], True,(0,255,0), 2, cv2.LINE_AA)\n",
    "        cv2.polylines(rgb,  [np.array([mesh_coord[p] for p in CHIN ], dtype=np.int32)], True, (0,0,255), 2, cv2.LINE_AA)\n",
    "        cv2.polylines(rgb,  [np.array([mesh_coord[p] for p in FOREHEAD ], dtype=np.int32)], True, (255,0,0), 2, cv2.LINE_AA)\n",
    "\n",
    "        plt.figure(4)\n",
    "        plt.imshow(rgb)\n",
    "\n",
    "\n",
    "\n",
    "#       Crop features\n",
    "        Lcheek = crop(mesh_coord,LEFT_CHEEK,rgb)\n",
    "        print(\"Left cheek dimension: \" + str(Lcheek[1]))\n",
    "        area_l = Lcheek[1][0] * Lcheek[1][1]\n",
    "        print(\"Area of left cheek: \" + str(area_l))\n",
    "        \n",
    "        Rcheek = crop(mesh_coord,RIGHT_CHEEK,rgb)\n",
    "        print(\"\\nRight cheek dimension: \" + str(Rcheek[1]))\n",
    "        area_r = Rcheek[1][0] * Rcheek[1][1]\n",
    "        print(\"Area of right cheek: \" + str(area_r))\n",
    "        \n",
    "        forehead = crop(mesh_coord,FOREHEAD,rgb)\n",
    "        print(\"\\nForehead dimension: \" + str(forehead[1]))\n",
    "        area_f = forehead[1][0] * forehead[1][1]\n",
    "        print(\"Area of forehead: \" + str(area_f))\n",
    "        \n",
    "        Chin = crop(mesh_coord,CHIN,rgb)\n",
    "        print(\"\\nChin dimension: \" + str(Chin[1]))\n",
    "        area_c = Chin[1][0] * Chin[1][1]\n",
    "        print(\"Area of chin: \" + str(area_c))\n",
    "        \n",
    "        print(\"=========================\")\n",
    "        \n",
    "        return Lcheek, Rcheek, forehead, Chin, area_l, area_r, area_f, area_c\n",
    "\n",
    "\n",
    "    except:\n",
    "        print(\"Cropped image too small\")\n",
    "        print(\"=======================\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a734c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)  # opening webcamera\n",
    "fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "print(\"Frame rate is: \" + str(fps))\n",
    "if not video_capture.isOpened():\n",
    "    print(\"Unable to access the camera\")\n",
    "else:\n",
    "    print(\"Access to the camera was successfully obtained\")\n",
    "\n",
    "print(\"Streaming started\")\n",
    "currentframe = 1\n",
    "while True:\n",
    "\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "        \n",
    "    #Saving the frames into a folder    \n",
    "    name = './Frames/tmp/frame' + str(currentframe) + '.jpg'\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img =  Image.fromarray(rgb)\n",
    "#     print(img)\n",
    "#     img = img.convert('RGB')\n",
    "    img.save(name,dpi = (600.0,600.0)) \n",
    "    currentframe +=1\n",
    "    \n",
    "    #Cloning the orginal image to be used later\n",
    "    clone = frame.copy()\n",
    "    clone_m = frame.copy()\n",
    "    clone_ho = frame.copy()\n",
    "    clone_ha = frame.copy()\n",
    "   \n",
    "\n",
    "    #Running MTCNN, HOG, and Haar simultaneously\n",
    "    m = mtcnn(frame,rgb)\n",
    "    ho = hog(frame,rgb)\n",
    "    ha = haar(frame,rgb)\n",
    "    \n",
    "   \n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    #Proceed only when all 3 methods can capture at least a face\n",
    "    \n",
    "    if m is not None and ho is not None and ha is not None:\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "        eye_detect = eye(frame, rgb)\n",
    "        \n",
    "        \n",
    "        \n",
    "         \n",
    "        #Detect eye + try to make sure it does detect the eye\n",
    "        if eye_detect is not None: \n",
    "            \n",
    "\n",
    "            print('\\nCalculating eye distance with 3 methods')\n",
    "            if eye_detect[2] and eye_detect[5] is not None:\n",
    "\n",
    "                #calcuting left eye distance with MTCNN\n",
    "                D_top_m = top_head(rgb, m, eye_detect[0], eye_detect[1])\n",
    "                print(\"\\nDistance of left eye to top of head (MTCNN with white text): \" + str(D_top_m))\n",
    "                \n",
    "                D_right_m = right_head(rgb,m, eye_detect[3], eye_detect[4])\n",
    "                print(\"Distance of right eye to right side of head (MTCNN with white text): \" + str(D_right_m))\n",
    "\n",
    "\n",
    "                D_left_m = left_head(rgb,m, eye_detect[0], eye_detect[1])\n",
    "                print(\"Distance of left eye to left side of head (MTCNN with white text): \" + str(D_left_m))\n",
    "\n",
    "\n",
    "                D_bot_m = bot_head(rgb,m, eye_detect[0], eye_detect[1]) \n",
    "                print(\"Distance of left eye to bottom of head (MTCNN with white text): \" + str(D_bot_m))\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "#                 (mX, mY) = midpoint((eye_detect[0], m[1]), (m, eye_detect[0], eye_detect[1]))\n",
    "#                 cv2.putText(rgb, \"{:.1f}in\".format((float(D_top_m))), (int(mX), int(mY - 10)),\n",
    "#                 cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 3)\n",
    "\n",
    "\n",
    "                #Calculating left eye distance with HOG\n",
    "                D_top_ho = top_head(rgb, ho, eye_detect[0], eye_detect[1])\n",
    "                print(\"\\nDistance of left eye to top of head (HOG with yellow text):\" + str(D_top_ho))\n",
    "                \n",
    "                D_right_ho = right_head(rgb,ho,eye_detect[3], eye_detect[4]) \n",
    "                print(\"Distance of right eye to right side of head (HOG with yellow text): \" + str(D_right_ho))\n",
    "\n",
    "\n",
    "                D_left_ho = left_head(rgb,ho,eye_detect[0], eye_detect[1])\n",
    "                print(\"Distance of left eye to left side of head (HOG with yellow text): \" + str(D_left_ho))\n",
    "\n",
    "\n",
    "                D_bot_ho = bot_head(rgb,ho,eye_detect[0], eye_detect[1]) \n",
    "                print(\"Distance of left eye to bottom of head (HOG with yellow text): \" + str(D_bot_ho))\n",
    "                \n",
    "               \n",
    "\n",
    "\n",
    "                (mX, mY) = midpoint((eye_detect[0], ho[1]), (eye_detect[0], eye_detect[1]))\n",
    "                cv2.putText(rgb, \"{:.1f}in\".format(D_top_ho), (int(mX + 10), int(mY + 10)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,0), 3)\n",
    "                \n",
    "                \n",
    "                \n",
    "                #Calculating left eye distance with haar\n",
    "                D_top_ha = top_head(rgb, ha,eye_detect[0], eye_detect[1])\n",
    "                print(\"\\nDistance of left eye to top of head (Haar with pink text): \" + str(D_top_ha))\n",
    "                \n",
    "                D_right_ha = right_head(rgb,ha,eye_detect[3], eye_detect[4]) \n",
    "                print(\"Distance of right eye to right side of head (Haar with pink text): \" + str(D_right_ha))\n",
    "\n",
    "\n",
    "                D_left_ha = left_head(rgb,ha,eye_detect[0], eye_detect[1])\n",
    "                print(\"Distance of left eye to left side of head (Haar with pink text): \" + str(D_left_ha))\n",
    "\n",
    "\n",
    "                D_bot_ha = bot_head(rgb,ha,eye_detect[0], eye_detect[1]) \n",
    "                print(\"Distance of left eye to bottom of head (Haar with pink text): \" + str(D_bot_ha))\n",
    "                \n",
    "               \n",
    "\n",
    "                (mX, mY) = midpoint((eye_detect[0], ha[1]), (eye_detect[0], eye_detect[1]))\n",
    "                cv2.putText(rgb, \"{:.1f}in\".format(D_top_ha), (int(ha[1]), int(mY - 10)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 2, (254,39,132), 3)  #pink text\n",
    "\n",
    "\n",
    "                \n",
    "            else:\n",
    "                print(\"Can't detect both eyes\")\n",
    "                D_top_m = 0\n",
    "                De_right_m = 0\n",
    "                D_bot_m = 0\n",
    "                D_left_m = 0\n",
    "                \n",
    "                \n",
    "                D_top_ho = 0\n",
    "                D_right_ho = 0\n",
    "                D_left_ho = 0\n",
    "                D_bot_ho = 0\n",
    "                \n",
    "                D_top_ha = 0\n",
    "                D_right_ha = 0\n",
    "                D_left_ha = 0\n",
    "                D_bot_ha = 0\n",
    "                \n",
    "\n",
    "        \n",
    "            \n",
    "                          \n",
    "            best = []\n",
    "            value = []\n",
    "\n",
    "            #compare top (trying to find best distance with face not cut)\n",
    "            if(D_top_m > D_top_ho) and D_top_m > D_top_ha:\n",
    "                ref_top_m = D_top_m - D_top_m\n",
    "                ref_top_ho = D_top_ho - D_top_m\n",
    "                ref_top_ha = D_top_ha - D_top_m\n",
    "                ref_top = m[1]\n",
    "                ref_top_name = \"MTCNN\"\n",
    "\n",
    "                \n",
    "                \n",
    "                print(\"\\n ---MTCNN is the highest and is the reference point: \" + str(D_top_m) + \"---\")\n",
    "                print(\"Distance to top of HOG wrt MTCNN = \" + str(ref_top_ho))\n",
    "                print(\"Distance to top of Haar wrt MTCNN = \" + str(ref_top_ha))\n",
    "            elif D_top_ho > D_top_ha and D_top_ho > D_top_m:\n",
    "                ref_top_m = D_top_m - D_top_ho\n",
    "                ref_top_ho = D_top_ho - D_top_ho\n",
    "                ref_top_ha = D_top_ha - D_top_ho\n",
    "                ref_top = ho[1]\n",
    "                ref_top_name = \"HOG\"\n",
    "                \n",
    "                \n",
    "                print(\"\\n --HOG is the highest and is the reference point: \" + str(D_top_ho) + \"---\")\n",
    "                print(\"Distance to top of MTCNN wrt HOG = \" + str(ref_top_m))\n",
    "                print(\"Distance to top of Haar wrt HOG = \" + str(ref_top_ha))\n",
    "                \n",
    "            elif D_top_ha > D_top_ho and D_top_ha > D_top_m:\n",
    "                ref_top_m = D_top_m - D_top_ha\n",
    "                ref_top_ho = D_top_ho - D_top_ha\n",
    "                ref_top_ha = D_top_ha - D_top_ha\n",
    "                ref_top = ha[1]\n",
    "                ref_top_name = \"Haar\"\n",
    "                \n",
    "                print(\"\\n --Haar is the highest and is the reference point: \" + str(D_top_ha) + \"---\")\n",
    "                print(\"Distance to top of MTCNN wrt Haar = \" + str(ref_top_m))\n",
    "                print(\"Distance to top of HOG wrt Haar = \" + str(ref_top_ho))\n",
    "                \n",
    "            else:\n",
    "                print(\"At least 2 detectors shared the same top distance\")\n",
    "\n",
    "           \n",
    "\n",
    "            #compare right\n",
    "            if D_right_m == 0 and D_right_ho == 0 and D_right_ha == 0:\n",
    "                print(\"No right eye detected\")\n",
    "                best.append(0)\n",
    "                value.append(0)\n",
    "                \n",
    "            elif(D_right_m > D_right_ho) and D_right_m > D_right_ha:\n",
    "                ref_right_m = D_right_m - D_right_m\n",
    "                ref_right_ho = D_right_ho - D_right_m\n",
    "                ref_right_ha = D_right_ha - D_right_m\n",
    "                ref_right = m[0]\n",
    "                ref_right_name = \"MTCNN\"\n",
    "            \n",
    "                \n",
    "                print(\"\\n ---MTCNN is the most right and is the reference point: \" + str(D_right_m) + \"---\")\n",
    "                print(\"Distance to right of HOG wrt MTCNN = \" + str(ref_right_ho))\n",
    "                print(\"Distance to right of Haar wrt MTCNN = \" + str(ref_right_ha))\n",
    "                \n",
    "                \n",
    "            elif D_right_ho > D_right_ha and D_right_ho > D_right_m:\n",
    "                ref_right_m = D_right_m - D_right_ho\n",
    "                ref_right_ho = D_right_ho - D_right_ho\n",
    "                ref_right_ha = D_right_ha - D_right_ho\n",
    "                ref_right = ho[0]\n",
    "                ref_right_name = \"HOG\"\n",
    "            \n",
    "                \n",
    "                print(\"\\n ---HOG is the most right and is the reference point: \" + str(D_right_ho) + \"---\")\n",
    "                print(\"Distance to right of MTCNN wrt HOG = \" + str(ref_right_m))\n",
    "                print(\"Distance to right of Haar wrt HOG = \" + str(ref_right_ha))\n",
    "            elif D_right_ha > D_right_ho and D_right_ha > D_right_m:\n",
    "                ref_right_m = D_right_m - D_right_ha\n",
    "                ref_right_ho = D_right_ho - D_right_ha\n",
    "                ref_right_ha = D_right_ha - D_right_ha\n",
    "                ref_right = ha[0]\n",
    "                ref_right_name = \"Haar\"\n",
    "            \n",
    "                \n",
    "                print(\"\\n ---Haar is the most right and is the reference point: \" + str(D_right_ha) + \"---\")\n",
    "                print(\"Distance to right of HOG wrt Haar = \" + str(ref_right_ho))\n",
    "                print(\"Distance to right of MTCNN wrt Haar = \" + str(ref_right_m))\n",
    "                \n",
    "            else:\n",
    "                print(\"At least 2 detectors shared the same right distance\")\n",
    "\n",
    "\n",
    "\n",
    "            #compare left\n",
    "            if D_left_m == 0 and D_left_ho == 0 and D_left_ha == 0:\n",
    "                print(\"No left eye detected\")\n",
    "                best.append(0)\n",
    "                value.append(0)\n",
    "            \n",
    "            elif(D_left_m > D_left_ho) and D_left_m > D_left_ha:\n",
    "                ref_left_m = D_left_m - D_left_m\n",
    "                ref_left_ho = D_left_ho - D_left_m\n",
    "                ref_left_ha = D_left_ha - D_left_m\n",
    "                ref_left = m[0] + m[2]\n",
    "                ref_left_name = \"MTCNN\"\n",
    "                \n",
    "                print(\"\\n ---MTCNN is the most left and is the reference point: \" + str(D_left_m) + \"---\")\n",
    "                print(\"Distance to left of HOG wrt MTCNN = \" + str(ref_left_ho))\n",
    "                print(\"Distance to left of Haar wrt MTCNN = \" + str(ref_left_ha))\n",
    "                \n",
    "            elif D_left_ho > D_left_ha and D_left_ho > D_left_m:\n",
    "                ref_left_m = D_left_m - D_left_ho\n",
    "                ref_left_ho = D_left_ho - D_left_ho\n",
    "                ref_left_ha = D_left_ha - D_left_ho\n",
    "                ref_left = ho[0] + ho[2]\n",
    "                ref_left_name = \"HOG\"\n",
    "                \n",
    "                print(\"\\n ---HOG is the most left and is the reference point: \" + str(D_left_ho) + \"---\")\n",
    "                print(\"Distance to left of MTCNN wrt HOG = \" + str(ref_left_m))\n",
    "                print(\"Distance to left of Haar wrt HOG = \" + str(ref_left_ha))\n",
    "            elif D_left_ha > D_left_ho and D_left_ha > D_left_m:\n",
    "                ref_left_m = D_left_m - D_left_ha\n",
    "                ref_left_ho = D_left_ho - D_left_ha\n",
    "                ref_left_ha = D_left_ha - D_left_ha\n",
    "                ref_left = ha[0] + ha[2]\n",
    "                ref_left_name = \"Haar\"\n",
    "            \n",
    "                \n",
    "                print(\"\\n ---Haar is the most left and is the reference point: \" + str(D_left_ha) + \"---\")\n",
    "                print(\"Distance to leftt of HOG wrt Haar = \" + str(ref_left_ho))\n",
    "                print(\"Distance to left of MTCNN wrt Haar = \" + str(ref_left_m))\n",
    "                \n",
    "            else:\n",
    "                print(\"At least 2 detectors shared the same left distance\")\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #compare bottom\n",
    "            if(D_bot_m > D_bot_ho) and D_bot_m > D_bot_ha:\n",
    "                ref_bot_m = D_bot_m - D_bot_m\n",
    "                ref_bot_ho = D_bot_ho - D_bot_m\n",
    "                ref_bot_ha = D_bot_ha - D_bot_m\n",
    "                ref_bot = m[1] + m[3]\n",
    "                ref_bot_name = \"MTCNN\"\n",
    "                \n",
    "                print(\"\\n --MTCNN is the lowest and is the reference point: \" + str(D_bot_m) + \"---\")\n",
    "                print(\"Distance to bottom of HOG wrt MTCNN = \" + str(ref_bot_ho))\n",
    "                print(\"Distance to bottom of Haar wrt MTCNN = \" + str(ref_bot_ha))\n",
    "            elif D_bot_ho > D_bot_ha and D_bot_ho > D_bot_m:\n",
    "                ref_bot_m = D_bot_m - D_bot_ho\n",
    "                ref_bot_ho = D_bot_ho - D_bot_ho\n",
    "                ref_bot_ha = D_bot_ha - D_bot_ho\n",
    "                ref_bot = ho[1] + ho[3]\n",
    "                ref_bot_name = \"HOG\"\n",
    "                \n",
    "                print(\"\\n --HOG is the lowest and is the reference point: \" + str(D_bot_ho) + \"---\")\n",
    "                print(\"Distance to bottom of MTCNN wrt HOG = \" + str(ref_bot_m))\n",
    "                print(\"Distance to bottom of Haar wrt HOG = \" + str(ref_bot_ha))\n",
    "            elif D_bot_ha > D_bot_ho and D_bot_ha > D_bot_m:\n",
    "                ref_bot_m = D_bot_m - D_bot_ha\n",
    "                ref_bot_ho = D_bot_ho - D_bot_ha\n",
    "                ref_bot_ha = D_bot_ha - D_bot_ha\n",
    "                ref_bot = ha[1] + ha[3]\n",
    "                ref_bot_name = \"Haar\"\n",
    "                \n",
    "                print(\"\\n --Haar is the lowest and is the reference point: \" + str(D_top_ha) + \"---\")\n",
    "                print(\"Distance to bottom of MTCNN wrt Haar = \" + str(ref_bot_m))\n",
    "                print(\"Distance to bottom of HOG wrt Haar = \" + str(ref_bot_ho))\n",
    "                \n",
    "            else:\n",
    "                print(\"At least 2 detectors shared the same bottom distance\")\n",
    "                \n",
    "            ref_m = ref_top_m + ref_bot_m + ref_left_m + ref_right_m\n",
    "            \n",
    "            print(\"\\nFinal comparison of MTCNN with other methods is: \" + str(ref_m))\n",
    "            \n",
    "            ref_ho = ref_top_ho + ref_bot_ho + ref_left_ho + ref_right_ho\n",
    "            print(\"Final comparison of HOG with other methods is: \" + str(ref_ho))\n",
    "            \n",
    "            ref_ha = ref_top_ha + ref_bot_ha + ref_left_ha + ref_right_ha\n",
    "            print(\"Final comparison of Haar with other methods is: \" + str(ref_ha))\n",
    "            \n",
    "            \n",
    "            \n",
    "                \n",
    "#             ref = []\n",
    "#             v = []\n",
    "\n",
    "#             print(\"The best detect is the combination of top = \" + ref_top_name + \", bottom = \" \n",
    "#                   + ref_bot_name + \", left = \" + ref_left_name + \", right = \" + ref_right_name)\n",
    "#             roi_color = clone[ref_top : ref_bot, ref_right : ref_left]\n",
    "#             print(\"Cropped face from optimal measurement\")\n",
    "#             feature_extraction = face_mesh(roi_color)\n",
    "#             roi_color = cv2.cvtColor(roi_color, cv2.COLOR_BGR2RGB)\n",
    "#             plt.figure()\n",
    "#             plt.imshow(roi_color)\n",
    "        \n",
    "            if ref_m > ref_ho and ref_m > ref_ha:\n",
    "                print(\"The best detector is MTCNN\")\n",
    "                \n",
    "            elif ref_ho > ref_m and ref_ho > ref_ha:\n",
    "                print(\"The best detector is HOG\")\n",
    "            \n",
    "            else: \n",
    "                print(\"Thes best detector is Haar\")\n",
    "                \n",
    "           \n",
    "                    \n",
    "          \n",
    "            roi_color_m = clone_m[m[1] : m[1] + m[3], m[0] : m[0] + m[2]]\n",
    "            print(\"\\nCropped face from MTCNN\")\n",
    "            feature_extraction_m = face_mesh(roi_color_m)\n",
    "            roi_color_m = cv2.cvtColor(roi_color_m, cv2.COLOR_BGR2RGB)\n",
    "#             plt.figure()\n",
    "#             plt.imshow(roi_color_m)\n",
    "\n",
    "            roi_color_ho = clone_ho[ho[1] - 15 : ho[1] + ho[3], ho[0] : ho[0] + ho[2]]\n",
    "\n",
    "#                 cv2.rectangle(clone_ho,(ho[0],ho[1]),(ho[0] + ho[2],ho[1]),(255,0,255),2)\n",
    "            print(\"\\nCropped face from HOG\")\n",
    "            feature_extraction_ho = face_mesh(roi_color_ho)\n",
    "            roi_color_ho = cv2.cvtColor(roi_color_ho, cv2.COLOR_BGR2RGB)\n",
    "#             plt.figure()\n",
    "#             plt.imshow(roi_color_ho)\n",
    "\n",
    "            roi_color_ha = clone_ha[ha[1] : ha[1] + ha[3], ha[0] : ha[0] + ha[2]]\n",
    "#                 cv2.rectangle(clone_ha,(ha[0],ha[1]),(ha[0] + ha[2],ha[1]),(0,255,0),2)\n",
    "            print(\"\\nCropped face from Haar\")\n",
    "            feature_extraction_ha = face_mesh(roi_color_ha)\n",
    "            roi_color_ha = cv2.cvtColor(roi_color_ha, cv2.COLOR_BGR2RGB)\n",
    "#             plt.figure()\n",
    "#             plt.imshow(roi_color_ha)\n",
    "            \n",
    "            \n",
    "            fig, (ax0, ax1, ax2) = plt.subplots(ncols=3, figsize=(8, 2))\n",
    "            \n",
    "            try:\n",
    "                ax0.imshow(feature_extraction_m[0][0])\n",
    "                ax0.set_title(\"MTCNN Left Cheek with area: \\n%s\" %feature_extraction_m[4])\n",
    "#                 ax0.axis('off')\n",
    "                \n",
    "            except:\n",
    "                ax0.set_title(\"Can't plot MTCNN left cheek\")\n",
    "                \n",
    "            try:\n",
    "                ax1.imshow(feature_extraction_ho[0][0])\n",
    "                ax1.set_title(\"HOG Left Cheek with area: \\n%s\" %feature_extraction_ho[4])\n",
    "#                 ax1.axis('off')\n",
    "            except: \n",
    "                ax1.set_title(\"Can't plot HOG left cheek\")\n",
    "                \n",
    "            try:\n",
    "                ax2.imshow(feature_extraction_ha[0][0])\n",
    "                ax2.set_title(\"Haar Left Cheek with area: \\n%s\" %feature_extraction_ha[4])\n",
    "#                 ax2.axis('off')\n",
    "                \n",
    "            except:\n",
    "                ax2.set_title(\"Can't plot Haar left cheek\")\n",
    "\n",
    "            fig.tight_layout()\n",
    "            \n",
    "            \n",
    "             \n",
    "            fig, (ax3, ax4, ax5) = plt.subplots(ncols=3, figsize=(8, 2))\n",
    "\n",
    "            try:\n",
    "                ax3.imshow(feature_extraction_m[1][0])\n",
    "                ax3.set_title(\"MTCNN Right Cheek with area: \\n%s\" %feature_extraction_m[5])\n",
    "#                 ax3.axis('off')\n",
    "                \n",
    "            except:\n",
    "                ax3.set_title(\"Can't plot MTCNN right cheek\")\n",
    "                    \n",
    "            try:\n",
    "\n",
    "                ax4.imshow(feature_extraction_ho[1][0])\n",
    "                ax4.set_title(\"HOG Right Cheek with area: \\n%s\" %feature_extraction_ho[5])\n",
    "#                 ax4.axis('off')\n",
    "            except:\n",
    "                ax4.set_title(\"Can't plot HOG right cheek\")\n",
    "                \n",
    "            try:\n",
    "                ax5.imshow(feature_extraction_ha[1][0])\n",
    "                ax5.set_title(\"Haar Right Cheek with area: \\n%s\" %feature_extraction_ha[5])\n",
    "#                 ax5.axis('off')\n",
    "            except:\n",
    "                ax5.set_title(\"Can't plot Haar right cheek\")\n",
    "            fig.tight_layout()\n",
    "            \n",
    "            \n",
    "             \n",
    "            fig, (ax6, ax7, ax8) = plt.subplots(ncols=3, figsize=(8, 2))\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                ax6.imshow(feature_extraction_m[2][0])\n",
    "                ax6.set_title(\"MTCNN Forehead with area: \\n%s\" %feature_extraction_m[6])\n",
    "#                 ax6.axis('off')\n",
    "            except:\n",
    "                ax6.set_title(\"Can't plot MTCNN forehead\")\n",
    "                \n",
    "            try:\n",
    "                \n",
    "                ax7.imshow(feature_extraction_ho[2][0])\n",
    "                ax7.set_title(\"HOG Forehead with area: \\n%s\" %feature_extraction_ho[6])\n",
    "#                 ax7.axis('off')\n",
    "            except:\n",
    "                ax7.set_title(\"Can't plot HOG forehead\")\n",
    "                \n",
    "            try:\n",
    "                ax8.imshow(feature_extraction_ha[2][0])\n",
    "                ax8.set_title(\"Haar Forehead with area: \\n%s\" %feature_extraction_ha[6])\n",
    "#                 ax8.axis('off')\n",
    "                \n",
    "            except:\n",
    "                ax8.set_title(\"Can't plot Haar forehead\")\n",
    "\n",
    "            fig.tight_layout()\n",
    "            \n",
    "            \n",
    "             \n",
    "            fig, (ax9, ax10, ax11) = plt.subplots(ncols=3, figsize=(8, 2))\n",
    "            try:\n",
    "                \n",
    "                ax9.imshow(feature_extraction_m[3][0])\n",
    "                ax9.set_title(\"MTCNN Chin with area: \\n%s\" %feature_extraction_m[7])\n",
    "#                 ax9.axis('off')\n",
    "            except:\n",
    "                ax9.set_title(\"Can't plot MTCNN chin\")\n",
    "            try:\n",
    "                \n",
    "                ax10.imshow(feature_extraction_ho[3][0])\n",
    "                ax10.set_title(\"HOG Chin with area: \\n%s\" %feature_extraction_ho[7])\n",
    "#                 ax10.axis('off')\n",
    "                \n",
    "            except:\n",
    "                ax10.set_title(\"Can't plot HOG chin\")\n",
    "                \n",
    "            try:\n",
    "                \n",
    "                ax11.imshow(feature_extraction_ha[3][0])\n",
    "                ax11.set_title(\"Haar Chin with area: \\n%s\" %feature_extraction_ha[7])\n",
    "#                 ax11.axis('off')\n",
    "                \n",
    "            except:\n",
    "                ax11.set_title(\"Can't plot Haar chin\")\n",
    "\n",
    "            fig.tight_layout()\n",
    "            \n",
    "               \n",
    "            plt.figure()\n",
    "            plt.imshow(rgb)\n",
    "            \n",
    "\n",
    "\n",
    "        else:\n",
    "            print(\"Failed Eye Detection\")\n",
    "            \n",
    "       \n",
    "\n",
    "\n",
    "    else: \n",
    "        print(\"No 3 face detection\")\n",
    "        \n",
    "    pyplot.imshow(rgb)\n",
    "    pyplot.show()  \n",
    "    \n",
    "    print(\"======================\")\n",
    "    \n",
    "        \n",
    "        # Display the resulting frame\n",
    "    cv2.imshow(\"Face detector - to quit press ESC\", frame)\n",
    "\n",
    "    # Exit with ESC\n",
    "    key = cv2.waitKey(1)\n",
    "    if key % 256 == 27: # ESC code\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Streaming ended\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
